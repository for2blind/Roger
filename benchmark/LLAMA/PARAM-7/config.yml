
version: 1.0
provider:
    name: openfaas
    gateway: http://serverless.siat.ac.cn:31112

functions:
    
    llama-7b-submod-6-param-7:
        namespace: cdgp
        lang: python3-http
        handler: ./llama-7b-submod-6
        image: k.harbor.siat.ac.cn/openfaas/cdgp-llama-7b-submod-6-param-7:1.0.3.roger
        requests:
            cpu: 1000m
            memory: 8Gi
        limits:
            cpu: 1000m
            memory: 64Gi
        environment:
            read_timeout: "0.71s"
            write_timeout: "0.71s"
            exec_timeout: "0.71s"
            retry_check: "true"
            debug: "false"
            infer_device: "cuda"
    
    llama-7b-submod-5-param-7:
        namespace: cdgp
        lang: python3-http
        handler: ./llama-7b-submod-5
        image: k.harbor.siat.ac.cn/openfaas/cdgp-llama-7b-submod-5-param-7:1.0.3.roger
        requests:
            cpu: 1000m
            memory: 8Gi
        limits:
            cpu: 1000m
            memory: 64Gi
        environment:
            read_timeout: "1.43s"
            write_timeout: "1.43s"
            exec_timeout: "1.43s"
            retry_check: "true"
            debug: "false"
            infer_device: "cuda"
    
    llama-7b-submod-4-param-7:
        namespace: cdgp
        lang: python3-http
        handler: ./llama-7b-submod-4
        image: k.harbor.siat.ac.cn/openfaas/cdgp-llama-7b-submod-4-param-7:1.0.3.roger
        requests:
            cpu: 1000m
            memory: 8Gi
        limits:
            cpu: 1000m
            memory: 64Gi
        environment:
            read_timeout: "2.14s"
            write_timeout: "2.14s"
            exec_timeout: "2.14s"
            retry_check: "true"
            debug: "false"
            infer_device: "cuda"
    
    llama-7b-submod-3-param-7:
        namespace: cdgp
        lang: python3-http
        handler: ./llama-7b-submod-3
        image: k.harbor.siat.ac.cn/openfaas/cdgp-llama-7b-submod-3-param-7:1.0.3.roger
        requests:
            cpu: 1000m
            memory: 8Gi
        limits:
            cpu: 1000m
            memory: 64Gi
        environment:
            read_timeout: "2.86s"
            write_timeout: "2.86s"
            exec_timeout: "2.86s"
            retry_check: "true"
            debug: "false"
            infer_device: "cuda"
    
    llama-7b-submod-2-param-7:
        namespace: cdgp
        lang: python3-http
        handler: ./llama-7b-submod-2
        image: k.harbor.siat.ac.cn/openfaas/cdgp-llama-7b-submod-2-param-7:1.0.3.roger
        requests:
            cpu: 1000m
            memory: 8Gi
        limits:
            cpu: 1000m
            memory: 64Gi
        environment:
            read_timeout: "3.57s"
            write_timeout: "3.57s"
            exec_timeout: "3.57s"
            retry_check: "true"
            debug: "false"
            infer_device: "cuda"
    
    llama-7b-submod-1-param-7:
        namespace: cdgp
        lang: python3-http
        handler: ./llama-7b-submod-1
        image: k.harbor.siat.ac.cn/openfaas/cdgp-llama-7b-submod-1-param-7:1.0.3.roger
        requests:
            cpu: 1000m
            memory: 8Gi
        limits:
            cpu: 1000m
            memory: 64Gi
        environment:
            read_timeout: "4.29s"
            write_timeout: "4.29s"
            exec_timeout: "4.29s"
            retry_check: "true"
            debug: "false"
            infer_device: "cuda"
    
    llama-7b-submod-0-param-7:
        namespace: cdgp
        lang: python3-http
        handler: ./llama-7b-submod-0
        image: k.harbor.siat.ac.cn/openfaas/cdgp-llama-7b-submod-0-param-7:1.0.3.roger
        requests:
            cpu: 1000m
            memory: 8Gi
        limits:
            cpu: 1000m
            memory: 64Gi
        environment:
            read_timeout: "5.0s"
            write_timeout: "5.0s"
            exec_timeout: "5.0s"
            retry_check: "true"
            debug: "false"
            infer_device: "cuda"
    